{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOOLS + CHAINS ==> LangChain AGENTS\n",
    "        - you have one big chain for task A [Summarization]\n",
    "        - you have one big chain for task B [Translation]\n",
    "        - you have one big chain for task C [Classification]\n",
    "        - In order to make the system more flexible, can use all these we i9ntroduce AGENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml, os, openai\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.agents import load_tools\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cadentials.yaml') as f:\n",
    "    credentials = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = credentials['OPENAI_API_KEY']\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = credentials['HUGGINGFACEHUB_API_TOKEN']\n",
    "os.environ['SERPAPI_API_KEY'] = credentials['SERPAPI_API_KEY']\n",
    "os.environ['ENGINE'] = credentials['ENGINE']\n",
    "\n",
    "openai.api_key = credentials['OPENAI_API_KEY']\n",
    "openai.api_base = credentials['OPENAI_API_BASE']\n",
    "openai.api_type = credentials['OPENAI_API_TYPE']\n",
    "openai.api_version = credentials['OPENAI_API_VERSION']\n",
    "openai.engine = credentials['ENGINE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! engine is not default parameter.\n",
      "                    engine was transferred to model_kwargs.\n",
      "                    Please confirm that engine is what you intended.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "                openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "                engine = os.environ[\"ENGINE\"],\n",
    "                model='gpt-3.5-turbo',\n",
    "                temperature=0.9, \n",
    "                max_tokens = 256\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools(\n",
    "                    [\"serpapi\", \"llm-math\"],  # we loaded 2 tools here\n",
    "                    llm=llm\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Calculator', 'Useful for when you need to answer questions about math.')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's explore about llm-math chain\n",
    "tools[1].name, tools[1].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='Calculator', description='Useful for when you need to answer questions about math.', args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, func=<bound method Chain.run of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, temperature=0.9, model_kwargs={'engine': 'dialog-gpt-35-turbo-16k-home-bu'}, openai_api_key='f79aa605fd2e44489e28d805d0204638', openai_api_base='', openai_organization='', openai_proxy='', max_tokens=256)))>, coroutine=<bound method Chain.arun of LLMMathChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, temperature=0.9, model_kwargs={'engine': 'dialog-gpt-35-turbo-16k-home-bu'}, openai_api_key='f79aa605fd2e44489e28d805d0204638', openai_api_base='', openai_organization='', openai_proxy='', max_tokens=256)))>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "                        tools, \n",
    "                        llm, \n",
    "                        agent=\"zero-shot-react-description\", \n",
    "                        verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\n",
      "Calculator: Useful for when you need to answer questions about math.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Search, Calculator]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThis question doesn't require any tools to answer. It is a simple greeting and does not require a search engine or calculator.\n",
      "Final Answer: No answer needed as it is a greeting.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No answer needed as it is a greeting.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Standard LLM Query\n",
    "agent.run(\"Hi How are you today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI can use a search engine to find the current United States President. Then I can calculate his current age divided by 2.\n",
      "Action: Search\n",
      "Action Input: \"current United States President\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mJoe Biden\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNow I need to find Joe Biden's current age.\n",
      "Action: Search\n",
      "Action Input: \"Joe Biden age\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m80 years\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNow I can calculate his current age divided by 2.\n",
      "Action: Calculator\n",
      "Action Input: 80 / 2\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 40.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: Joe Biden's current age raised divided by 2 is 40.0.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Joe Biden's current age raised divided by 2 is 40.0.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"Who is the United States President? What is his current age raised divided by 2?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find the average age in the United States and the age of the current US President. Then I can calculate the difference between the two.\n",
      "Action: Search\n",
      "Action Input: \"average age in the United States\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[\"The U.S. is a country of 50 states covering a vast swath of North America, with Alaska in the northwest and Hawaii extending the nation’s presence into the Pacific Ocean. Major Atlantic Coast cities are New York, a global finance and culture center, and capital Washington, DC. Midwestern metropolis Chicago is known for influential architecture and on the west coast, Los Angeles' Hollywood is famed for filmmaking. ― Google\", 'United States type: Country in North America.', 'United States kgmid: /m/09c7w0.', 'United States capital: Washington, D.C..', 'United States co2_emissions_per_capita: 14.67 metric tons (2019).', 'United States electricity_consumption_per_capita: 12,993.97 kWh (2014).', 'United States energy_use_per_capita: 6,804.00 kg of oil equivalent (2015).', 'United States fertility_rate: 1.64 births per woman (2020).', 'United States gdp_growth_rate: 5.9% annual change (2021).', 'United States gross_domestic_product: 23.32 trillion USD (2021).', \"The nation's median age increased by 0.2 years to 38.9 years between 2021 and 2022, according to Vintage 2022 Population Estimates released ...\"]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to refine my search query to specifically find the average age in the United States.\n",
      "Action: Search\n",
      "Action Input: \"average age in the United States 2022\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m38.9 years\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now have the average age in the United States. \n",
      "Thought: I need to find the age of the current US President.\n",
      "Action: Search\n",
      "Action Input: \"age of current US President\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m80 years\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer. \n",
      "Final Answer: The average age in the United States is 38.9 years. The current US President is 80 years old. The difference between the two is 41.1 years.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The average age in the United States is 38.9 years. The current US President is 80 years old. The difference between the two is 41.1 years.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What is the average age in the United States? How much less is that then the age of the current US President?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# more complex agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools(\n",
    "                    [\"serpapi\", \"llm-math\",\"wikipedia\",\"terminal\"], \n",
    "                    llm=llm\n",
    "                    )\n",
    "agent = initialize_agent(\n",
    "                        tools, \n",
    "                        llm, \n",
    "                        agent=\"zero-shot-react-description\", \n",
    "                        verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\n",
      "Calculator: Useful for when you need to answer questions about math.\n",
      "Wikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "terminal: Run shell commands on this MacOS machine.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Search, Calculator, Wikipedia, terminal]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find out the name of the head of DeepMind.\n",
      "Action: Wikipedia\n",
      "Action Input: \"DeepMind\"\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mPage: Google DeepMind\n",
      "Summary: DeepMind Technologies Limited, doing business as Google DeepMind, is a British-American artificial intelligence research laboratory which serves as a subsidiary of Google. Founded in the UK in 2010, it was acquired by Google in 2014, becoming a wholly owned subsidiary of Google parent company Alphabet Inc. after Google's corporate restructuring in 2015. The company is based in London, with research centres in Canada, France, and the United States.\n",
      "Google DeepMind has created neural network models that learn how to play video games in a fashion similar to that of humans, as well as Neural Turing machines (neural networks that can access external memory like a conventional Turing machine),, resulting in a computer that loosely resembles short-term memory in the human brain.DeepMind made headlines in 2016 after its AlphaGo program beat a human professional Go player Lee Sedol, a world champion, in a five-game match, which was the subject of a documentary film. A more general program, AlphaZero, beat the most powerful programs playing go, chess and shogi (Japanese chess) after a few days of play against itself using reinforcement learning. In 2020, DeepMind made significant advances in the problem of protein folding with AlphaFold. In July 2022, it was announced that over 200 million predicted protein structures, representing virtually all known proteins, would be released on the AlphaFold database.DeepMind posted a blog post on 28 April 2022 on a single visual language model (VLM) named Flamingo that can accurately describe a picture of something with just a few training images. In July 2022, DeepMind announced the development of DeepNash, a model-free multi-agent reinforcement learning system capable of playing the board game Stratego at the level of a human expert. The company merged with Google AI's Google Brain division to become Google DeepMind in April 2023.\n",
      "\n",
      "Page: AlphaGo\n",
      "Summary: AlphaGo is a computer program that plays the board game Go. It was developed by the London-based DeepMind Technologies, an acquired subsidiary of Google (now Alphabet Inc.). Subsequent versions of AlphaGo became increasingly powerful, including a version that competed under the name Master. After retiring from competitive play, AlphaGo Master was succeeded by an even more powerful version known as AlphaGo Zero, which was completely self-taught without learning from human games. AlphaGo Zero was then generalized into a program known as AlphaZero, which played additional games, including chess and shogi.  AlphaZero has in turn been succeeded by a program known as MuZero which learns without being taught the rules.\n",
      "AlphaGo and its successors use a Monte Carlo tree search algorithm to find its moves based on knowledge previously acquired by machine learning, specifically by an artificial neural network (a deep learning method) by extensive training, both from human and computer play. A neural network is trained to identify the best moves and the winning percentages of these moves. This neural network improves the strength of the tree search, resulting in stronger move selection in the next iteration.\n",
      "In October 2015, in a match against Fan Hui, the original AlphaGo became the first computer Go program to beat a human professional Go player without handicap on a full-sized 19×19 board. In March 2016, it beat Lee Sedol in a five-game match, the first time a computer Go program has beaten a 9-dan professional without handicap. Although it lost to Lee Sedol in the fourth game, Lee resigned in the final game, giving a final score of 4 games to 1 in favour of AlphaGo. In recognition of the victory, AlphaGo was awarded an honorary 9-dan by the Korea Baduk Association. The lead up and the challenge match with Lee Sedol were documented in a documentary film also titled AlphaGo, directed by Greg Kohs. The win by AlphaGo was chosen by Science as one of the Breakthrough of the Year runners-up on 22 December 2016.At the 2017 Future \u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have found the information about DeepMind, but I still need to find out who the current head of DeepMind is.\n",
      "Action: Wikipedia\n",
      "Action Input: \"DeepMind\"\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mPage: Google DeepMind\n",
      "Summary: DeepMind Technologies Limited, doing business as Google DeepMind, is a British-American artificial intelligence research laboratory which serves as a subsidiary of Google. Founded in the UK in 2010, it was acquired by Google in 2014, becoming a wholly owned subsidiary of Google parent company Alphabet Inc. after Google's corporate restructuring in 2015. The company is based in London, with research centres in Canada, France, and the United States.\n",
      "Google DeepMind has created neural network models that learn how to play video games in a fashion similar to that of humans, as well as Neural Turing machines (neural networks that can access external memory like a conventional Turing machine),, resulting in a computer that loosely resembles short-term memory in the human brain.DeepMind made headlines in 2016 after its AlphaGo program beat a human professional Go player Lee Sedol, a world champion, in a five-game match, which was the subject of a documentary film. A more general program, AlphaZero, beat the most powerful programs playing go, chess and shogi (Japanese chess) after a few days of play against itself using reinforcement learning. In 2020, DeepMind made significant advances in the problem of protein folding with AlphaFold. In July 2022, it was announced that over 200 million predicted protein structures, representing virtually all known proteins, would be released on the AlphaFold database.DeepMind posted a blog post on 28 April 2022 on a single visual language model (VLM) named Flamingo that can accurately describe a picture of something with just a few training images. In July 2022, DeepMind announced the development of DeepNash, a model-free multi-agent reinforcement learning system capable of playing the board game Stratego at the level of a human expert. The company merged with Google AI's Google Brain division to become Google DeepMind in April 2023.\n",
      "\n",
      "Page: AlphaGo\n",
      "Summary: AlphaGo is a computer program that plays the board game Go. It was developed by the London-based DeepMind Technologies, an acquired subsidiary of Google (now Alphabet Inc.). Subsequent versions of AlphaGo became increasingly powerful, including a version that competed under the name Master. After retiring from competitive play, AlphaGo Master was succeeded by an even more powerful version known as AlphaGo Zero, which was completely self-taught without learning from human games. AlphaGo Zero was then generalized into a program known as AlphaZero, which played additional games, including chess and shogi.  AlphaZero has in turn been succeeded by a program known as MuZero which learns without being taught the rules.\n",
      "AlphaGo and its successors use a Monte Carlo tree search algorithm to find its moves based on knowledge previously acquired by machine learning, specifically by an artificial neural network (a deep learning method) by extensive training, both from human and computer play. A neural network is trained to identify the best moves and the winning percentages of these moves. This neural network improves the strength of the tree search, resulting in stronger move selection in the next iteration.\n",
      "In October 2015, in a match against Fan Hui, the original AlphaGo became the first computer Go program to beat a human professional Go player without handicap on a full-sized 19×19 board. In March 2016, it beat Lee Sedol in a five-game match, the first time a computer Go program has beaten a 9-dan professional without handicap. Although it lost to Lee Sedol in the fourth game, Lee resigned in the final game, giving a final score of 4 games to 1 in favour of AlphaGo. In recognition of the victory, AlphaGo was awarded an honorary 9-dan by the Korea Baduk Association. The lead up and the challenge match with Lee Sedol were documented in a documentary film also titled AlphaGo, directed by Greg Kohs. The win by AlphaGo was chosen by Science as one of the Breakthrough of the Year runners-up on 22 December 2016.At the 2017 Future \u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI am not finding the specific information about the head of DeepMind on the Wikipedia page. I should try a different approach.\n",
      "Action: Search\n",
      "Action Input: \"current head of DeepMind\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mHassabis is the CEO and co-founder of DeepMind, a machine learning AI startup, founded in London in 2010 with Shane Legg and Mustafa Suleyman. Hassabis met Legg when both were postdocs at the Gatsby Computational Neuroscience Unit, and he and Suleyman had been friends through family.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have found the answer. The current head of DeepMind is Demis Hassabis.\n",
      "Final Answer: Demis Hassabis\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Demis Hassabis'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"Who is the head of DeepMind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI'm not exactly sure what DeepMind is, so I think I should start by searching for information about it.\n",
      "Action: Search\n",
      "Action Input: \"DeepMind\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[{'title': 'Google DeepMind unites researchers in bid to create an ImageNet of robot actions', 'link': 'https://techcrunch.com/2023/10/05/google-deepmind-unites-researchers-in-bid-to-create-an-imagenet-of-robot-actions/', 'source': 'TechCrunch', 'date': '13 hours ago', 'thumbnail': 'https://serpapi.com/searches/651fa41c8e02e4e86f2da72c/images/7619d063c6d718997eb2ef6ff28e93a23645a2f292515359.jpeg'}, {'title': \"DeepMind cofounder is tired of 'knee-jerk bad takes' about AI\", 'link': 'https://venturebeat.com/ai/deepmind-cofounder-is-tired-of-knee-jerk-bad-takes-about-ai/', 'source': 'VentureBeat', 'date': '16 hours ago', 'thumbnail': 'https://serpapi.com/searches/651fa41c8e02e4e86f2da72c/images/7619d063c6d718991fb90b700486c6b3d4692be5a5fb410e.jpeg'}, {'title': 'Scaling up learning across many different robot types', 'link': 'https://www.deepmind.com/blog/scaling-up-learning-across-many-different-robot-types', 'source': 'Google DeepMind', 'date': '2 days ago', 'thumbnail': 'https://serpapi.com/searches/651fa41c8e02e4e86f2da72c/images/7619d063c6d718991e8f1ab7a4bae7cdbffe7f858f2eda53.jpeg'}, {'title': \"Broken 'guardrails' for AI systems lead to push for new safety measures\", 'link': 'https://www.ft.com/content/f23e59a2-4cad-43a5-aed9-3aea6426d0f2', 'source': 'Financial Times', 'date': '14 hours ago', 'thumbnail': 'https://serpapi.com/searches/651fa41c8e02e4e86f2da72c/images/7619d063c6d718999dd31b2e4505ccbeb3c694d6ec820c9b.jpeg'}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mBased on the search results, DeepMind appears to be a company or research organization that is involved in AI and robotics. Let me check Wikipedia to get more information.\n",
      "Action: Wikipedia\n",
      "Action Input: \"DeepMind\"\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mPage: Google DeepMind\n",
      "Summary: DeepMind Technologies Limited, doing business as Google DeepMind, is a British-American artificial intelligence research laboratory which serves as a subsidiary of Google. Founded in the UK in 2010, it was acquired by Google in 2014, becoming a wholly owned subsidiary of Google parent company Alphabet Inc. after Google's corporate restructuring in 2015. The company is based in London, with research centres in Canada, France, and the United States.\n",
      "Google DeepMind has created neural network models that learn how to play video games in a fashion similar to that of humans, as well as Neural Turing machines (neural networks that can access external memory like a conventional Turing machine),, resulting in a computer that loosely resembles short-term memory in the human brain.DeepMind made headlines in 2016 after its AlphaGo program beat a human professional Go player Lee Sedol, a world champion, in a five-game match, which was the subject of a documentary film. A more general program, AlphaZero, beat the most powerful programs playing go, chess and shogi (Japanese chess) after a few days of play against itself using reinforcement learning. In 2020, DeepMind made significant advances in the problem of protein folding with AlphaFold. In July 2022, it was announced that over 200 million predicted protein structures, representing virtually all known proteins, would be released on the AlphaFold database.DeepMind posted a blog post on 28 April 2022 on a single visual language model (VLM) named Flamingo that can accurately describe a picture of something with just a few training images. In July 2022, DeepMind announced the development of DeepNash, a model-free multi-agent reinforcement learning system capable of playing the board game Stratego at the level of a human expert. The company merged with Google AI's Google Brain division to become Google DeepMind in April 2023.\n",
      "\n",
      "Page: AlphaGo\n",
      "Summary: AlphaGo is a computer program that plays the board game Go. It was developed by the London-based DeepMind Technologies, an acquired subsidiary of Google (now Alphabet Inc.). Subsequent versions of AlphaGo became increasingly powerful, including a version that competed under the name Master. After retiring from competitive play, AlphaGo Master was succeeded by an even more powerful version known as AlphaGo Zero, which was completely self-taught without learning from human games. AlphaGo Zero was then generalized into a program known as AlphaZero, which played additional games, including chess and shogi.  AlphaZero has in turn been succeeded by a program known as MuZero which learns without being taught the rules.\n",
      "AlphaGo and its successors use a Monte Carlo tree search algorithm to find its moves based on knowledge previously acquired by machine learning, specifically by an artificial neural network (a deep learning method) by extensive training, both from human and computer play. A neural network is trained to identify the best moves and the winning percentages of these moves. This neural network improves the strength of the tree search, resulting in stronger move selection in the next iteration.\n",
      "In October 2015, in a match against Fan Hui, the original AlphaGo became the first computer Go program to beat a human professional Go player without handicap on a full-sized 19×19 board. In March 2016, it beat Lee Sedol in a five-game match, the first time a computer Go program has beaten a 9-dan professional without handicap. Although it lost to Lee Sedol in the fourth game, Lee resigned in the final game, giving a final score of 4 games to 1 in favour of AlphaGo. In recognition of the victory, AlphaGo was awarded an honorary 9-dan by the Korea Baduk Association. The lead up and the challenge match with Lee Sedol were documented in a documentary film also titled AlphaGo, directed by Greg Kohs. The win by AlphaGo was chosen by Science as one of the Breakthrough of the Year runners-up on 22 December 2016.At the 2017 Future \u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mBased on the search results and the Wikipedia page, DeepMind is a British-American artificial intelligence research laboratory. It was founded in the UK in 2010 and was acquired by Google in 2014. DeepMind has made significant advances in AI, including creating neural network models that learn how to play video games and developing AlphaGo, a program that beat human professional Go players. It has also made progress in protein folding and developed models like Flamingo and DeepNash. DeepMind merged with Google AI's Google Brain division in April 2023 to become Google DeepMind.\n",
      "\n",
      "Final Answer: DeepMind is an AI research laboratory that was acquired by Google. It has made notable contributions in various areas of AI and has developed programs like AlphaGo.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DeepMind is an AI research laboratory that was acquired by Google. It has made notable contributions in various areas of AI and has developed programs like AlphaGo.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What is DeepMind ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find out the year DeepMind was founded and add 50 years to it. Then I can determine if this year will have AGI.\n",
      "Action: Search\n",
      "Action Input: \"DeepMind founding year\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m2010, London, United Kingdom\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have found the founding year of DeepMind.\n",
      "Action: Calculator\n",
      "Action Input: 2010 + 50\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 2060\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: The year DeepMind was founded plus 50 years is 2060. Whether or not this year will have AGI is unknown.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The year DeepMind was founded plus 50 years is 2060. Whether or not this year will have AGI is unknown.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"Take the year DeepMind was founded and add 50 years. Will this year have AGI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI can use the terminal to list the files in the current directory.\n",
      "Action: terminal\n",
      "Action Input: ls\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1 langchain-intro.ipynb\n",
      "12 langchain talk to csv.ipynb\n",
      "2 langchain-tools-and-chains.ipynb\n",
      "3 chatgpt-langchain-integration.ipynb\n",
      "4 conversation with memory.ipynb\n",
      "5 langchain-meets-huggingface.ipynb\n",
      "6 use-hf-models-local.ipynb\n",
      "7 summarization system.ipynb\n",
      "8 langchain agents.ipynb\n",
      "\u001b[34massets\u001b[m\u001b[m\n",
      "cadentials.yaml\n",
      "\u001b[34mdata\u001b[m\u001b[m\n",
      "image.png\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the list of files in the current directory.\n",
      "Final Answer: The files in the current directory are: langchain-intro.ipynb, langchain talk to csv.ipynb, langchain-tools-and-chains.ipynb, chatgpt-langchain-integration.ipynb, conversation with memory.ipynb, langchain-meets-huggingface.ipynb, use-hf-models-local.ipynb, summarization system.ipynb, langchain agents.ipynb, assets, credentials.yaml, data, and image.png.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The files in the current directory are: langchain-intro.ipynb, langchain talk to csv.ipynb, langchain-tools-and-chains.ipynb, chatgpt-langchain-integration.ipynb, conversation with memory.ipynb, langchain-meets-huggingface.ipynb, use-hf-models-local.ipynb, summarization system.ipynb, langchain agents.ipynb, assets, credentials.yaml, data, and image.png.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What files are in my current directory ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
